# tools/translator_tool.py

import streamlit as st
import google.generativeai as genai
from google.cloud import speech
from google.api_core.client_options import ClientOptions
from streamlit_mic_recorder import mic_recorder

# ===============================================================
# è£œåŠ©é–¢æ•° (å¤‰æ›´ãªã—ã€ç§ãŸã¡ã®ä¿¡é ¼ã§ãã‚‹æŠ€èƒ½)
# ===============================================================
def transcribe_audio(audio_bytes, api_key):
    if not audio_bytes or not api_key: return None
    try:
        client_options = ClientOptions(api_key=api_key)
        client = speech.SpeechClient(client_options=client_options)
        audio = speech.RecognitionAudio(content=audio_bytes)
        config = speech.RecognitionConfig(language_code="ja-JP")
        response = client.recognize(config=config, audio=audio)
        if response.results: return response.results[0].alternatives[0].transcript
    except Exception as e:
        st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ã”ç¢ºèªãã ã•ã„ã€‚è©³ç´°: {e}")
    return None

def translate_text_with_gemini(text_to_translate, api_key):
    if not text_to_translate or not api_key: return None
    try:
        genai.configure(api_key=api_key)
        system_prompt = """
        ã‚ãªãŸã¯ã€è¨€èªã®å£ã‚’ä¹—ã‚Šè¶Šãˆã‚‹æ‰‹åŠ©ã‘ã‚’ã™ã‚‹ã€éå¸¸ã«å„ªç§€ãªç¿»è¨³ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰æ¸¡ã•ã‚ŒãŸæ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€æµ·å¤–ã®è¦ªã—ã„å‹äººã¨ã®ä¼šè©±ã§ä½¿ã‚ã‚Œã‚‹ã‚ˆã†ãªã€è‡ªç„¶ã§ã€ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã§ã‚ã‚ŠãªãŒã‚‰ç¤¼å„€æ­£ã—ãã€ãã—ã¦ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªè‹±èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚
        - éå¸¸ã«ç¡¬ã„è¡¨ç¾ã‚„ã€ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã®ã‚ˆã†ãªç¿»è¨³ã¯é¿ã‘ã¦ãã ã•ã„ã€‚
        - ç¿»è¨³å¾Œã®è‹±èªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚ä»–ã®è¨€è‘‰ã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚
        """
        model = genai.GenerativeModel('gemini-1.5-flash-latest', system_instruction=system_prompt)
        response = model.generate_content(text_to_translate)
        return response.text.strip()
    except Exception as e:
        st.error(f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼: AIã¨ã®é€šä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
    return None


# ===============================================================
# å°‚é–€å®¶ã®ãƒ¡ã‚¤ãƒ³ã®ä»•äº‹ (ç§ãŸã¡ã®å¡æ™ºã®çµæ™¶)
# ===============================================================
def show_tool(gemini_api_key, speech_api_key):
    st.header("ğŸ¤ ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ç¿»è¨³ãƒ„ãƒ¼ãƒ«", divider='rainbow')

    # --- çŠ¶æ…‹ç®¡ç†ã®åˆæœŸåŒ– (å¤‰æ›´ãªã—) ---
    if "translator_results" not in st.session_state:
        st.session_state.translator_results = []
    if "translator_last_mic_id" not in st.session_state:
        st.session_state.translator_last_mic_id = None
    if "translator_last_text" not in st.session_state:
        st.session_state.translator_last_text = ""

    # --- UIã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®è¡¨ç¤º (å¤‰æ›´ãªã—) ---
    st.info("ãƒã‚¤ã‚¯ã§æ—¥æœ¬èªã‚’è©±ã™ã‹ã€ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚è‡ªç„¶ãªè‹±èªã«ç¿»è¨³ã—ã¾ã™ã€‚")
    col1, col2 = st.columns([1, 2])
    with col1:
        audio_info = mic_recorder(start_prompt="ğŸ¤ è©±ã—å§‹ã‚ã‚‹", stop_prompt="â¹ï¸ ç¿»è¨³ã™ã‚‹", key='translator_mic')
    with col2:
        text_prompt = st.text_input("ã¾ãŸã¯ã€ã“ã“ã«æ—¥æœ¬èªã‚’å…¥åŠ›ã—ã¦Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„...", key="translator_text")

    # --- çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢ ---
    if st.session_state.translator_results:
        st.write("---")
        for i, result in enumerate(st.session_state.translator_results):
            with st.container(border=True):
                st.caption(f"ç¿»è¨³å±¥æ­´ No.{len(st.session_state.translator_results) - i}")
                st.markdown(f"**ğŸ‡¯ğŸ‡µ ã‚ãªãŸã®å…¥åŠ›:**\n> {result['original']}")
                st.markdown(f"**ğŸ‡ºğŸ‡¸ AIã®ç¿»è¨³:**\n> {result['translated']}")
        
        # â˜…â˜…â˜… ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã“ã“ã«é›†ç´„ â˜…â˜…â˜…
        if st.button("ç¿»è¨³å±¥æ­´ã‚’ã‚¯ãƒªã‚¢", key="clear_translator_history"):
            st.session_state.translator_results = []
            # ã€Œåœ°ç¸›éœŠã€ã®ç™ºç”Ÿã‚’é˜²ããŸã‚ã®ã€æ¥µã‚ã¦é‡è¦ãªä¸€è¡Œ
            st.session_state.translator_last_text = text_prompt
            st.rerun()


    # â˜…â˜…â˜… ã“ã“ãŒã€ç§ãŸã¡ã®æœ€çµ‚ä½œæˆ¦ã®ã€æ ¸å¿ƒéƒ¨ã§ã™ â˜…â˜…â˜…

    # --- Step 1: æ–°ã—ã„å…¥åŠ›ã®ã€Œæ¤œçŸ¥ã€ã«å¾¹ã™ã‚‹ ---
    japanese_text_to_process = None
    
    # æ–°ã—ã„éŸ³å£°å…¥åŠ›ã‹ï¼Ÿ
    if audio_info and audio_info['id'] != st.session_state.translator_last_mic_id:
        with st.spinner("éŸ³å£°ã‚’æ—¥æœ¬èªã«å¤‰æ›ä¸­..."):
            text_from_mic = transcribe_audio(audio_info['bytes'], speech_api_key)
        if text_from_mic:
            japanese_text_to_process = text_from_mic
            # æ¤œçŸ¥ã—ãŸç¬é–“ã«ã€IDã¨ãƒ†ã‚­ã‚¹ãƒˆã®ä¸¡æ–¹ã‚’ã€Œå‡¦ç†æ¸ˆã¿ã€ã¨ã—ã¦è¨˜æ†¶
            st.session_state.translator_last_mic_id = audio_info['id']
            st.session_state.translator_last_text = text_from_mic

    # æ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‹ï¼Ÿ
    elif text_prompt and text_prompt != st.session_state.translator_last_text:
        japanese_text_to_process = text_prompt
        # æ¤œçŸ¥ã—ãŸç¬é–“ã«ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€Œå‡¦ç†æ¸ˆã¿ã€ã¨ã—ã¦è¨˜æ†¶
        st.session_state.translator_last_text = text_prompt

    # --- Step 2: ã€Œæ¤œçŸ¥ã•ã‚ŒãŸæ–°ã—ã„å…¥åŠ›ãŒã‚ã‚‹å ´åˆã®ã¿ã€ã€ç¿»è¨³å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ ---
    if japanese_text_to_process:
        if not gemini_api_key: st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Gemini APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("AIãŒæœ€é©ãªè‹±èªã‚’è€ƒãˆã¦ã„ã¾ã™..."):
                translated_text = translate_text_with_gemini(japanese_text_to_process, gemini_api_key)
            if translated_text:
                st.session_state.translator_results.insert(0, {"original": japanese_text_to_process, "translated": translated_text})
                st.rerun()
            else:
                # ç¿»è¨³ã«å¤±æ•—ã—ãŸå ´åˆã¯ã€åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã§å†è©¦è¡Œã§ãã‚‹ã‚ˆã†ã€è¨˜æ†¶ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹
                st.session_state.translator_last_text = ""
                st.warning("ç¿»è¨³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
