# tools/translator_tool.py

import streamlit as st
import google.generativeai as genai
from google.cloud import speech
from google.api_core.client_options import ClientOptions
from streamlit_mic_recorder import mic_recorder

# (è£œåŠ©é–¢æ•° transcribe_audio, translate_text_with_gemini ã¯å¤‰æ›´ãªã—)
def transcribe_audio(audio_bytes, api_key):
    if not audio_bytes or not api_key: return None
    try:
        client_options = ClientOptions(api_key=api_key)
        client = speech.SpeechClient(client_options=client_options)
        audio = speech.RecognitionAudio(content=audio_bytes)
        config = speech.RecognitionConfig(language_code="ja-JP")
        response = client.recognize(config=config, audio=audio)
        if response.results: return response.results[0].alternatives[0].transcript
    except Exception as e:
        st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ã”ç¢ºèªãã ã•ã„ã€‚è©³ç´°: {e}")
    return None

def translate_text_with_gemini(text_to_translate, api_key):
    if not text_to_translate or not api_key: return None
    try:
        genai.configure(api_key=api_key)
        system_prompt = """
        ã‚ãªãŸã¯ã€è¨€èªã®å£ã‚’ä¹—ã‚Šè¶Šãˆã‚‹æ‰‹åŠ©ã‘ã‚’ã™ã‚‹ã€éå¸¸ã«å„ªç§€ãªç¿»è¨³ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰æ¸¡ã•ã‚ŒãŸæ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€æµ·å¤–ã®è¦ªã—ã„å‹äººã¨ã®ä¼šè©±ã§ä½¿ã‚ã‚Œã‚‹ã‚ˆã†ãªã€è‡ªç„¶ã§ã€ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã§ã‚ã‚ŠãªãŒã‚‰ç¤¼å„€æ­£ã—ãã€ãã—ã¦ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªè‹±èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚
        - éå¸¸ã«ç¡¬ã„è¡¨ç¾ã‚„ã€ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã®ã‚ˆã†ãªç¿»è¨³ã¯é¿ã‘ã¦ãã ã•ã„ã€‚
        - ç¿»è¨³å¾Œã®è‹±èªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚ä»–ã®è¨€è‘‰ã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚
        """
        model = genai.GenerativeModel('gemini-1.5-flash-latest', system_instruction=system_prompt)
        response = model.generate_content(text_to_translate)
        return response.text.strip()
    except Exception as e:
        st.error(f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼: AIã¨ã®é€šä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
    return None


# ===============================================================
# å°‚é–€å®¶ã®ãƒ¡ã‚¤ãƒ³ã®ä»•äº‹ (å¸ä»¤å¡” app.py ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹)
# ===============================================================
def show_tool(gemini_api_key, speech_api_key):
    st.header("ğŸ¤ ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ç¿»è¨³ãƒ„ãƒ¼ãƒ«", divider='rainbow')

    # --- çŠ¶æ…‹ç®¡ç†ã®åˆæœŸåŒ– ---
    if "translator_results" not in st.session_state:
        st.session_state.translator_results = []
    if "translator_last_mic_id" not in st.session_state:
        st.session_state.translator_last_mic_id = None
    # â˜…â˜…â˜… è«–ç†é˜²å¾¡ã®ãŸã‚ã®è¨˜æ†¶å ´æ‰€ â˜…â˜…â˜…
    if "translator_last_text" not in st.session_state:
        st.session_state.translator_last_text = ""

    # (UIã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®è¡¨ç¤ºéƒ¨åˆ†ã¯å¤‰æ›´ãªã—)
    st.info("ãƒã‚¤ã‚¯ã§æ—¥æœ¬èªã‚’è©±ã™ã‹ã€ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚è‡ªç„¶ãªè‹±èªã«ç¿»è¨³ã—ã¾ã™ã€‚")
    col1, col2 = st.columns([1, 2])
    with col1:
        audio_info = mic_recorder(start_prompt="ğŸ¤ è©±ã—å§‹ã‚ã‚‹", stop_prompt="â¹ï¸ ç¿»è¨³ã™ã‚‹", key='translator_mic')
    with col2:
        text_prompt = st.text_input("ã¾ãŸã¯ã€ã“ã“ã«æ—¥æœ¬èªã‚’å…¥åŠ›ã—ã¦Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„...", key="translator_text")
    if st.session_state.translator_results:
        st.write("---")
        for i, result in enumerate(st.session_state.translator_results):
            with st.container(border=True):
                st.caption(f"ç¿»è¨³å±¥æ­´ No.{len(st.session_state.translator_results) - i}")
                st.markdown(f"**ğŸ‡¯ğŸ‡µ ã‚ãªãŸã®å…¥åŠ›:**\n> {result['original']}")
                st.markdown(f"**ğŸ‡ºğŸ‡¸ AIã®ç¿»è¨³:**\n> {result['translated']}")
        if st.button("ç¿»è¨³å±¥æ­´ã‚’ã‚¯ãƒªã‚¢", key="clear_translator_history"):
            st.session_state.translator_results = []
            st.session_state.translator_last_text = "" # å±¥æ­´ã‚¯ãƒªã‚¢æ™‚ã‚‚è¨˜æ†¶ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.rerun()

    # --- å…¥åŠ›ãŒã‚ã£ãŸå ´åˆã®å‡¦ç†ãƒ•ãƒ­ãƒ¼ ---
    japanese_text = None
    is_new_input = False

    # éŸ³å£°å…¥åŠ›ã®åˆ¤å®š
    if audio_info and audio_info['id'] != st.session_state.translator_last_mic_id:
        st.session_state.translator_last_mic_id = audio_info['id']
        if not speech_api_key: st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Speech-to-Text APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("éŸ³å£°ã‚’æ—¥æœ¬èªã«å¤‰æ›ä¸­..."):
                japanese_text = transcribe_audio(audio_info['bytes'], speech_api_key)
                if japanese_text: is_new_input = True

    # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã®åˆ¤å®š (è«–ç†é˜²å¾¡)
    elif text_prompt and text_prompt != st.session_state.translator_last_text:
        japanese_text = text_prompt
        is_new_input = True

    # --- ç¿»è¨³å‡¦ç†ã®å®Ÿè¡Œ ---
    if is_new_input and japanese_text:
        if not gemini_api_key: st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Gemini APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("AIãŒæœ€é©ãªè‹±èªã‚’è€ƒãˆã¦ã„ã¾ã™..."):
                translated_text = translate_text_with_gemini(japanese_text, gemini_api_key)
            if translated_text:
                st.session_state.translator_results.insert(0, {"original": japanese_text, "translated": translated_text})
                
                # â˜…â˜…â˜… ã“ã“ãŒã€ç§ãŸã¡ã®å®Œç’§ãªäºŒæ®µæ§‹ãˆã§ã™ â˜…â˜…â˜…
                # 1. è«–ç†é˜²å¾¡ï¼šæ¬¡ã®ãƒ«ãƒ¼ãƒ—ã‚’é˜²ããŸã‚ã€å‡¦ç†ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è¨˜æ†¶ã™ã‚‹
                st.session_state.translator_last_text = japanese_text
                # 2. ç‰©ç†é˜²å¾¡ï¼šå…¥åŠ›ãƒœãƒƒã‚¯ã‚¹ã‚’ç‰©ç†çš„ã«ã‚¯ãƒªã‚¢ã—ã€UXã‚’å‘ä¸Šã•ã›ã€ãƒ«ãƒ¼ãƒ—ã®å¼•ãé‡‘ã‚’æ–­ã¤
                st.session_state.translator_text = ""
                
                st.rerun()
            else:
                st.warning("ç¿»è¨³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
